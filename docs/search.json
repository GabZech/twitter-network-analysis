[
  {
    "objectID": "src/analysis.html",
    "href": "src/analysis.html",
    "title": "Twitter Network Analysis",
    "section": "",
    "text": "First, let’s define some helper functions to be used later.\n\n\nCode\nimport json\nimport re\n\nimport numpy as np\nimport pandas as pd\n\ndef extract_missing_usernames(df, username_column):\n    pattern = r\"RT @([A-Za-z0-9_]+):\"\n    usernames = []\n    for index, row in df.iterrows():\n        match = re.search(pattern, row[\"retweet_text\"])\n        if match:\n            usernames.append(match.group(1))\n        else:\n            usernames.append(row[username_column])\n    df[username_column] = usernames\n\n    return df\n\n\ndef get_time_range(df):\n    \"\"\"Get the time range of the DataFrame\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    date_lang : str, optional\n        Language of the date, by default \"de_DE\"\n\n    Returns\n    -------\n    str\n        Start date of the DataFrame\n    str\n        End date of the DataFrame\n    \"\"\"\n    df.retweet_created_at = df.retweet_created_at.astype(\"datetime64[ns, UTC]\")\n    start_date = df.retweet_created_at.min().strftime(\"%B %e, %Y\")\n    end_date = df.retweet_created_at.max().strftime(\"%B %e, %Y\")\n\n    return start_date, end_date\n\n\ndef get_largest_values(df, col_name, n):\n    \"\"\"Get the n largest values of a column in a DataFrame\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    col_name : str\n        Name of the column to be queried\n    n : int\n        Number of largest values to be returned (i.e. number of rows)\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the n largest values of the column\n    \"\"\"\n    top = df.sort_values(col_name, ascending=False).head(n)\n\n    # put col_name as first column\n    cols = top.columns.tolist()\n    cols = cols[-1:] + cols[:-1]\n    top = top[cols]\n\n    return top\n\n\ndef get_top_users(df, df_authors, column_name, n):\n    \"\"\"Get the top n users with their profiles based on a column in a DataFrame\n    Values of the column are standardized so that the largest value is 1.0\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    df_authors : pandas.DataFrame\n        DataFrame with the usernames and names of authors\n    column_name : str\n        Name of the column to be queried\n    n : int\n        Number of largest values to be returned (i.e. number of rows)\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the n largest values of the column\n    \"\"\"\n    column_name_std = column_name + \" (normalised)\"\n    df[column_name_std] = df[column_name] / max(df[column_name])\n    df = get_largest_values(df, column_name, n)\n    df = add_profile_url(df, \"username\")\n    df = pd.merge(df, df_authors, on=\"username\", how=\"left\")\n    df = df.round(5)\n    df.index = np.arange(1, len(df) + 1)\n    df = df[[column_name, column_name_std, \"username\", \"name\", \"profile_url\"]]\n    return df\n\n\ndef get_authors_name(df):\n    \"\"\"Get the usernames and names of retweet authors and tweet authors\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the usernames and names of retweet authors and tweet authors\n    \"\"\"\n    retweet_authors = df[[\"retweet_author_username\", \"retweet_author_name\"]].copy()\n    retweet_authors.rename(\n        columns={\"retweet_author_username\": \"username\", \"retweet_author_name\": \"name\"},\n        inplace=True,\n    )\n\n    tweet_authors = df[[\"tweet_author_username\", \"tweet_author_name\"]].copy()\n    tweet_authors.rename(\n        columns={\"tweet_author_username\": \"username\", \"tweet_author_name\": \"name\"},\n        inplace=True,\n    )\n\n    authors = pd.concat([retweet_authors, tweet_authors])\n    authors = authors.drop_duplicates(subset=[\"username\"], keep=\"last\").reset_index(\n        drop=True\n    )\n\n    return authors\n\n\ndef add_profile_url(df, username_col):\n    df[\"profile_url\"] = \"https://twitter.com/\" + df[username_col]\n\n    return df\n\n\nNow let’s prepare the data and print some relevant information about it.\n\n\nCode\n# load and clean dataset\ndf = pd.read_parquet(\"data/raw/all_tweets_lehrkraeftebildung.parquet\")\ndf.replace([\"NaN\", \"nan\", \"None\", \"\"], np.NaN, inplace=True)\ndf = extract_missing_usernames(df, \"tweet_author_username\")\n\n# get information about the retweets\nstart_date, end_date = get_time_range(df)\nsearch_words = \"(Lehrkräftebildung OR Lehrerbildung OR Lehrkräfte OR Lehrkräftefortbildung OR Seiteneinstieg OR Quereinstieg OR Lehramt)\"\nquery_conds = \"(is:retweet OR is:quote) lang:de\"\n\n# drop retweets with missing usernames\nold_df_len = df.shape[0]\ntry:\n    missing_usernames = df.tweet_author_username.isnull().value_counts()[True]\nexcept KeyError:\n    missing_usernames = 0\ndf = df.dropna(subset=[\"tweet_author_username\"])\n\n\n# Print info about dataset\nprint(f\"Number of total retweets in this dataset: \\n{old_df_len}\")\nprint(f\"\\nTime range of the retweets:\\n{start_date} - {end_date}\")\nprint(f\"\\nKeywords* used to collect the retweets:\\n{search_words}\")\nprint(f\"\\nQuery conditions used to collect the retweets:\\n{query_conds}\")\nprint(f\"\\nNumber of retweets with missing usernames for the original tweeter: {missing_usernames}\\nThese are being dropped from the analysis. New total of retweets: {len(df)}\")\n\n\nNumber of total retweets in this dataset: \n11027\n\nTime range of the retweets:\nFebruary 23, 2023 - April  1, 2023\n\nKeywords* used to collect the retweets:\n(Lehrkräftebildung OR Lehrerbildung OR Lehrkräfte OR Lehrkräftefortbildung OR Seiteneinstieg OR Quereinstieg OR Lehramt)\n\nQuery conditions used to collect the retweets:\n(is:retweet OR is:quote) lang:de\n\nNumber of retweets with missing usernames for the original tweeter: 199\nThese are being dropped from the analysis. New total of retweets: 10828"
  },
  {
    "objectID": "src/analysis.html#data-preparation",
    "href": "src/analysis.html#data-preparation",
    "title": "Twitter Network Analysis",
    "section": "",
    "text": "First, let’s define some helper functions to be used later.\n\n\nCode\nimport json\nimport re\n\nimport numpy as np\nimport pandas as pd\n\ndef extract_missing_usernames(df, username_column):\n    pattern = r\"RT @([A-Za-z0-9_]+):\"\n    usernames = []\n    for index, row in df.iterrows():\n        match = re.search(pattern, row[\"retweet_text\"])\n        if match:\n            usernames.append(match.group(1))\n        else:\n            usernames.append(row[username_column])\n    df[username_column] = usernames\n\n    return df\n\n\ndef get_time_range(df):\n    \"\"\"Get the time range of the DataFrame\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    date_lang : str, optional\n        Language of the date, by default \"de_DE\"\n\n    Returns\n    -------\n    str\n        Start date of the DataFrame\n    str\n        End date of the DataFrame\n    \"\"\"\n    df.retweet_created_at = df.retweet_created_at.astype(\"datetime64[ns, UTC]\")\n    start_date = df.retweet_created_at.min().strftime(\"%B %e, %Y\")\n    end_date = df.retweet_created_at.max().strftime(\"%B %e, %Y\")\n\n    return start_date, end_date\n\n\ndef get_largest_values(df, col_name, n):\n    \"\"\"Get the n largest values of a column in a DataFrame\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    col_name : str\n        Name of the column to be queried\n    n : int\n        Number of largest values to be returned (i.e. number of rows)\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the n largest values of the column\n    \"\"\"\n    top = df.sort_values(col_name, ascending=False).head(n)\n\n    # put col_name as first column\n    cols = top.columns.tolist()\n    cols = cols[-1:] + cols[:-1]\n    top = top[cols]\n\n    return top\n\n\ndef get_top_users(df, df_authors, column_name, n):\n    \"\"\"Get the top n users with their profiles based on a column in a DataFrame\n    Values of the column are standardized so that the largest value is 1.0\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n    df_authors : pandas.DataFrame\n        DataFrame with the usernames and names of authors\n    column_name : str\n        Name of the column to be queried\n    n : int\n        Number of largest values to be returned (i.e. number of rows)\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the n largest values of the column\n    \"\"\"\n    column_name_std = column_name + \" (normalised)\"\n    df[column_name_std] = df[column_name] / max(df[column_name])\n    df = get_largest_values(df, column_name, n)\n    df = add_profile_url(df, \"username\")\n    df = pd.merge(df, df_authors, on=\"username\", how=\"left\")\n    df = df.round(5)\n    df.index = np.arange(1, len(df) + 1)\n    df = df[[column_name, column_name_std, \"username\", \"name\", \"profile_url\"]]\n    return df\n\n\ndef get_authors_name(df):\n    \"\"\"Get the usernames and names of retweet authors and tweet authors\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        DataFrame to be queried\n\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame with the usernames and names of retweet authors and tweet authors\n    \"\"\"\n    retweet_authors = df[[\"retweet_author_username\", \"retweet_author_name\"]].copy()\n    retweet_authors.rename(\n        columns={\"retweet_author_username\": \"username\", \"retweet_author_name\": \"name\"},\n        inplace=True,\n    )\n\n    tweet_authors = df[[\"tweet_author_username\", \"tweet_author_name\"]].copy()\n    tweet_authors.rename(\n        columns={\"tweet_author_username\": \"username\", \"tweet_author_name\": \"name\"},\n        inplace=True,\n    )\n\n    authors = pd.concat([retweet_authors, tweet_authors])\n    authors = authors.drop_duplicates(subset=[\"username\"], keep=\"last\").reset_index(\n        drop=True\n    )\n\n    return authors\n\n\ndef add_profile_url(df, username_col):\n    df[\"profile_url\"] = \"https://twitter.com/\" + df[username_col]\n\n    return df\n\n\nNow let’s prepare the data and print some relevant information about it.\n\n\nCode\n# load and clean dataset\ndf = pd.read_parquet(\"data/raw/all_tweets_lehrkraeftebildung.parquet\")\ndf.replace([\"NaN\", \"nan\", \"None\", \"\"], np.NaN, inplace=True)\ndf = extract_missing_usernames(df, \"tweet_author_username\")\n\n# get information about the retweets\nstart_date, end_date = get_time_range(df)\nsearch_words = \"(Lehrkräftebildung OR Lehrerbildung OR Lehrkräfte OR Lehrkräftefortbildung OR Seiteneinstieg OR Quereinstieg OR Lehramt)\"\nquery_conds = \"(is:retweet OR is:quote) lang:de\"\n\n# drop retweets with missing usernames\nold_df_len = df.shape[0]\ntry:\n    missing_usernames = df.tweet_author_username.isnull().value_counts()[True]\nexcept KeyError:\n    missing_usernames = 0\ndf = df.dropna(subset=[\"tweet_author_username\"])\n\n\n# Print info about dataset\nprint(f\"Number of total retweets in this dataset: \\n{old_df_len}\")\nprint(f\"\\nTime range of the retweets:\\n{start_date} - {end_date}\")\nprint(f\"\\nKeywords* used to collect the retweets:\\n{search_words}\")\nprint(f\"\\nQuery conditions used to collect the retweets:\\n{query_conds}\")\nprint(f\"\\nNumber of retweets with missing usernames for the original tweeter: {missing_usernames}\\nThese are being dropped from the analysis. New total of retweets: {len(df)}\")\n\n\nNumber of total retweets in this dataset: \n11027\n\nTime range of the retweets:\nFebruary 23, 2023 - April  1, 2023\n\nKeywords* used to collect the retweets:\n(Lehrkräftebildung OR Lehrerbildung OR Lehrkräfte OR Lehrkräftefortbildung OR Seiteneinstieg OR Quereinstieg OR Lehramt)\n\nQuery conditions used to collect the retweets:\n(is:retweet OR is:quote) lang:de\n\nNumber of retweets with missing usernames for the original tweeter: 199\nThese are being dropped from the analysis. New total of retweets: 10828"
  }
]