{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Twitter Network Analysis\n",
        "\n",
        "## Data preparation\n",
        "\n",
        "First, let's define some helper functions to be used later.\n"
      ],
      "id": "cb6e7a9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def extract_missing_usernames(df, username_column):\n",
        "    pattern = r\"RT @([A-Za-z0-9_]+):\"\n",
        "    usernames = []\n",
        "    for index, row in df.iterrows():\n",
        "        match = re.search(pattern, row[\"retweet_text\"])\n",
        "        if match:\n",
        "            usernames.append(match.group(1))\n",
        "        else:\n",
        "            usernames.append(row[username_column])\n",
        "    df[username_column] = usernames\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_time_range(df):\n",
        "    \"\"\"Get the time range of the DataFrame\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame to be queried\n",
        "    date_lang : str, optional\n",
        "        Language of the date, by default \"de_DE\"\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Start date of the DataFrame\n",
        "    str\n",
        "        End date of the DataFrame\n",
        "    \"\"\"\n",
        "    df.retweet_created_at = df.retweet_created_at.astype(\"datetime64[ns, UTC]\")\n",
        "    start_date = df.retweet_created_at.min().strftime(\"%B %e, %Y\")\n",
        "    end_date = df.retweet_created_at.max().strftime(\"%B %e, %Y\")\n",
        "\n",
        "    return start_date, end_date\n",
        "\n",
        "\n",
        "def get_largest_values(df, col_name, n):\n",
        "    \"\"\"Get the n largest values of a column in a DataFrame\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame to be queried\n",
        "    col_name : str\n",
        "        Name of the column to be queried\n",
        "    n : int\n",
        "        Number of largest values to be returned (i.e. number of rows)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with the n largest values of the column\n",
        "    \"\"\"\n",
        "    top = df.sort_values(col_name, ascending=False).head(n)\n",
        "\n",
        "    # put col_name as first column\n",
        "    cols = top.columns.tolist()\n",
        "    cols = cols[-1:] + cols[:-1]\n",
        "    top = top[cols]\n",
        "\n",
        "    return top\n",
        "\n",
        "\n",
        "def get_top_users(df, df_authors, column_name, n):\n",
        "    \"\"\"Get the top n users with their profiles based on a column in a DataFrame\n",
        "    Values of the column are standardized so that the largest value is 1.0\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame to be queried\n",
        "    df_authors : pandas.DataFrame\n",
        "        DataFrame with the usernames and names of authors\n",
        "    column_name : str\n",
        "        Name of the column to be queried\n",
        "    n : int\n",
        "        Number of largest values to be returned (i.e. number of rows)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with the n largest values of the column\n",
        "    \"\"\"\n",
        "    column_name_std = column_name + \" (normalised)\"\n",
        "    df[column_name_std] = df[column_name] / max(df[column_name])\n",
        "    df = get_largest_values(df, column_name, n)\n",
        "    df = add_profile_url(df, \"username\")\n",
        "    df = pd.merge(df, df_authors, on=\"username\", how=\"left\")\n",
        "    df = df.round(5)\n",
        "    df.index = np.arange(1, len(df) + 1)\n",
        "    df = df[[column_name, column_name_std, \"username\", \"name\", \"profile_url\"]]\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_authors_name(df):\n",
        "    \"\"\"Get the usernames and names of retweet authors and tweet authors\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame to be queried\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pandas.DataFrame\n",
        "        DataFrame with the usernames and names of retweet authors and tweet authors\n",
        "    \"\"\"\n",
        "    retweet_authors = df[[\"retweet_author_username\", \"retweet_author_name\"]].copy()\n",
        "    retweet_authors.rename(\n",
        "        columns={\"retweet_author_username\": \"username\", \"retweet_author_name\": \"name\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    tweet_authors = df[[\"tweet_author_username\", \"tweet_author_name\"]].copy()\n",
        "    tweet_authors.rename(\n",
        "        columns={\"tweet_author_username\": \"username\", \"tweet_author_name\": \"name\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    authors = pd.concat([retweet_authors, tweet_authors])\n",
        "    authors = authors.drop_duplicates(subset=[\"username\"], keep=\"last\").reset_index(\n",
        "        drop=True\n",
        "    )\n",
        "\n",
        "    return authors\n",
        "\n",
        "\n",
        "def add_profile_url(df, username_col):\n",
        "    df[\"profile_url\"] = \"https://twitter.com/\" + df[username_col]\n",
        "\n",
        "    return df"
      ],
      "id": "918291ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's prepare the data and print some relevant information about it.\n"
      ],
      "id": "0e1501fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load and clean dataset\n",
        "df = pd.read_parquet(\"../data/raw/all_tweets_lehrkraeftebildung.parquet\")\n",
        "df.replace([\"NaN\", \"nan\", \"None\", \"\"], np.NaN, inplace=True)\n",
        "df = extract_missing_usernames(df, \"tweet_author_username\")\n",
        "\n",
        "# get information about the retweets\n",
        "start_date, end_date = get_time_range(df)\n",
        "search_words = \"(Lehrkräftebildung OR Lehrerbildung OR Lehrkräfte OR Lehrkräftefortbildung OR Seiteneinstieg OR Quereinstieg OR Lehramt)\"\n",
        "query_conds = \"(is:retweet OR is:quote) lang:de\"\n",
        "\n",
        "# drop retweets with missing usernames\n",
        "old_df_len = df.shape[0]\n",
        "try:\n",
        "    missing_usernames = df.tweet_author_username.isnull().value_counts()[True]\n",
        "except KeyError:\n",
        "    missing_usernames = 0\n",
        "df = df.dropna(subset=[\"tweet_author_username\"])\n",
        "\n",
        "\n",
        "# Print info about dataset\n",
        "print(f\"Number of total retweets in this dataset: \\n{old_df_len}\")\n",
        "print(f\"\\nTime range of the retweets:\\n{start_date} - {end_date}\")\n",
        "print(f\"\\nKeywords* used to collect the retweets:\\n{search_words}\")\n",
        "print(f\"\\nQuery conditions used to collect the retweets:\\n{query_conds}\")\n",
        "print(f\"\\nNumber of retweets with missing usernames for the original tweeter: {missing_usernames}\\nThese are being dropped from the analysis. New total of retweets: {len(df)}\")"
      ],
      "id": "73d3db90",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from graph_tool.all import *\n",
        "\n",
        "def get_adj_m(df):\n",
        "    adj = pd.crosstab(df['retweet_author_username'],\n",
        "    df['tweet_author_username'])\n",
        "    idx = adj.index.union(adj.columns)\n",
        "    adj = adj.reindex(index=idx, columns=idx, fill_value=0).to_numpy()\n",
        "\n",
        "    idx = adj.nonzero()\n",
        "    weights = adj[idx]\n",
        "    return idx, weights\n",
        "\n",
        "idx, weights = get_adj_m(df)\n",
        "\n",
        "g = Graph()\n",
        "g.add_edge_list(np.transpose(idx))\n",
        "ew = g.new_edge_property(\"int\")\n",
        "ew.a = weights\n",
        "g.edge_properties[\"weight\"] = ew"
      ],
      "id": "97205981",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "graph_draw(g)"
      ],
      "id": "570ad6f7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}